<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 3 Análisis de Componentes Principales | AMAT- Ciencia de Datos y Machine Learning</title>
  <meta name="description" content="AMAT: Ciencia de Datos y Machine Learning" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 3 Análisis de Componentes Principales | AMAT- Ciencia de Datos y Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="AMAT: Ciencia de Datos y Machine Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 3 Análisis de Componentes Principales | AMAT- Ciencia de Datos y Machine Learning" />
  
  <meta name="twitter:description" content="AMAT: Ciencia de Datos y Machine Learning" />
  

<meta name="author" content="Karina Lizette Gamboa Puente" />
<meta name="author" content="Oscar Arturo Bringas López" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="scoping.html"/>
<link rel="next" href="clustering-no-jerárquico.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/d3v3-3.5.3/./d3v3.min.js"></script>
<link href="libs/d3heatmapcore-0.0.0/heatmapcore.css" rel="stylesheet" />
<script src="libs/d3heatmapcore-0.0.0/heatmapcore.js"></script>
<script src="libs/d3v3-tip-0.6.6/index.js"></script>
<script src="libs/d3heatmap-binding-0.9.0/d3heatmap.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li|
|:-:|  
<center>Ciencia de Datos y Machine Learning</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructores"><i class="fa fa-check"></i>Instructores</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-curso"><i class="fa fa-check"></i>Estructura del curso</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-curso"><i class="fa fa-check"></i>Alcances del curso</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duración-y-evaluación-del-curso"><i class="fa fa-check"></i>Duración y evaluación del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-dinámica-de-clase"><i class="fa fa-check"></i>Recursos y dinámica de clase</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html"><i class="fa fa-check"></i><b>1</b> Introducción a Ciencia de Datos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#qué-es-ciencia-de-datos"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es Ciencia de Datos?</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#definiendo-conceptos"><i class="fa fa-check"></i>Definiendo conceptos:</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#objetivos"><i class="fa fa-check"></i><b>1.2</b> Objetivos</a></li>
<li class="chapter" data-level="1.3" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#requisitos"><i class="fa fa-check"></i><b>1.3</b> Requisitos</a></li>
<li class="chapter" data-level="1.4" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aplicaciones"><i class="fa fa-check"></i><b>1.4</b> Aplicaciones</a></li>
<li class="chapter" data-level="1.5" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#tipos-de-algoritmos"><i class="fa fa-check"></i><b>1.5</b> Tipos de algoritmos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aprendizaje-supervisado"><i class="fa fa-check"></i><b>1.5.1</b> Aprendizaje supervisado</a></li>
<li class="chapter" data-level="1.5.2" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>1.5.2</b> Aprendizaje no supervisado</a></li>
<li class="chapter" data-level="1.5.3" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aprendizaje-por-refuerzo"><i class="fa fa-check"></i><b>1.5.3</b> Aprendizaje por refuerzo</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#ciclo-de-un-proyecto"><i class="fa fa-check"></i><b>1.6</b> Ciclo de un proyecto</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scoping.html"><a href="scoping.html"><i class="fa fa-check"></i><b>2</b> Scoping</a>
<ul>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#definir-objetivos"><i class="fa fa-check"></i>Definir objetivo(s)</a></li>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#qué-acciones-o-intervenciones-existen-que-serán-mejoradas-a-través-de-este-proyecto"><i class="fa fa-check"></i>¿Qué acciones o intervenciones existen que serán mejoradas a través de este proyecto?</a></li>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#qué-datos-tenemos-y-cuáles-necesitamos"><i class="fa fa-check"></i>¿Qué datos tenemos y cuáles necesitamos?</a></li>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#cuál-es-el-análisis-que-necesitamos-hacer"><i class="fa fa-check"></i>¿Cuál es el análisis que necesitamos hacer?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>3</b> Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>3.1</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="3.2" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#construcción-matemática"><i class="fa fa-check"></i><b>3.2</b> Construcción matemática</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#eigenvalores-y-eigenvectores"><i class="fa fa-check"></i><b>3.2.1</b> Eigenvalores y eigenvectores</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#implementación-en-r"><i class="fa fa-check"></i><b>3.3</b> Implementación en R</a></li>
<li class="chapter" data-level="3.4" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#reducción-de-dimensión"><i class="fa fa-check"></i><b>3.4</b> Reducción de dimensión</a></li>
<li class="chapter" data-level="3.5" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>3.5</b> Representación gráfica</a></li>
<li class="chapter" data-level="3.6" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#predicciones"><i class="fa fa-check"></i><b>3.6</b> Predicciones</a></li>
<li class="chapter" data-level="3.7" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#ejercicios"><i class="fa fa-check"></i><b>3.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html"><i class="fa fa-check"></i><b>4</b> Clustering No Jerárquico</a>
<ul>
<li class="chapter" data-level="4.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#cálculo-de-distancia"><i class="fa fa-check"></i><b>4.1</b> Cálculo de distancia</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#distancias-homogéneas"><i class="fa fa-check"></i><b>4.1.1</b> Distancias homogéneas</a></li>
<li class="chapter" data-level="4.1.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#distancias-mixtas"><i class="fa fa-check"></i><b>4.1.2</b> Distancias mixtas</a></li>
<li class="chapter" data-level="4.1.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#visualización-de-distancias"><i class="fa fa-check"></i><b>4.1.3</b> Visualización de distancias</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#k---means"><i class="fa fa-check"></i><b>4.2</b> K - means</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#ajuste-de-modelo-cómo-funciona-el-algortimo"><i class="fa fa-check"></i><b>4.2.1</b> Ajuste de modelo: ¿Cómo funciona el algortimo?</a></li>
<li class="chapter" data-level="4.2.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#calidad-de-ajuste"><i class="fa fa-check"></i><b>4.2.2</b> Calidad de ajuste</a></li>
<li class="chapter" data-level="4.2.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#cómo-seleccionamos-k"><i class="fa fa-check"></i><b>4.2.3</b> ¿Cómo seleccionamos K?</a></li>
<li class="chapter" data-level="4.2.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-1"><i class="fa fa-check"></i><b>4.2.4</b> Implementación en R</a></li>
<li class="chapter" data-level="4.2.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#warnings"><i class="fa fa-check"></i><b>4.2.5</b> Warnings</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#partitioning-around-medoids-pam"><i class="fa fa-check"></i><b>4.3</b> Partitioning Around Medoids (PAM)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#algoritmo-pam"><i class="fa fa-check"></i><b>4.3.1</b> Algoritmo PAM</a></li>
<li class="chapter" data-level="4.3.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-2"><i class="fa fa-check"></i><b>4.3.2</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#clustering-large-applications-clara"><i class="fa fa-check"></i><b>4.4</b> Clustering Large Applications (CLARA)</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-3"><i class="fa fa-check"></i><b>4.4.1</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#dbscan"><i class="fa fa-check"></i><b>4.5</b> DBSCAN</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#algoritmo"><i class="fa fa-check"></i><b>4.5.1</b> Algoritmo</a></li>
<li class="chapter" data-level="4.5.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#estimación-de-parámetros"><i class="fa fa-check"></i><b>4.5.2</b> Estimación de parámetros</a></li>
<li class="chapter" data-level="4.5.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-4"><i class="fa fa-check"></i><b>4.5.3</b> Implementación en R</a></li>
<li class="chapter" data-level="4.5.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#ventajas-de-dbscan"><i class="fa fa-check"></i><b>4.5.4</b> Ventajas de DBSCAN</a></li>
<li class="chapter" data-level="4.5.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#aplicación-dbscan"><i class="fa fa-check"></i><b>4.5.5</b> Aplicación DBSCAN</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#comparación-de-algoritmos"><i class="fa fa-check"></i><b>4.6</b> Comparación de algoritmos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html"><i class="fa fa-check"></i><b>5</b> Clustering Jerárquico</a>
<ul>
<li class="chapter" data-level="5.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#agglomerative-divise-clustering"><i class="fa fa-check"></i><b>5.1</b> Agglomerative &amp; Divise Clustering</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#algoritmo-1"><i class="fa fa-check"></i><b>5.1.1</b> Algoritmo</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#implementación-en-r-5"><i class="fa fa-check"></i><b>5.2</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#preparación-y-estructuración-de-datos"><i class="fa fa-check"></i><b>5.2.1</b> Preparación y estructuración de datos</a></li>
<li class="chapter" data-level="5.2.2" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#medidas-de-disimilaridad"><i class="fa fa-check"></i><b>5.2.2</b> Medidas de (di)similaridad</a></li>
<li class="chapter" data-level="5.2.3" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#función-liga"><i class="fa fa-check"></i><b>5.2.3</b> Función Liga</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#dendogramas"><i class="fa fa-check"></i><b>5.3</b> Dendogramas</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#selección-de-grupos"><i class="fa fa-check"></i><b>5.3.1</b> Selección de grupos</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#comparación-de-dendogramas"><i class="fa fa-check"></i><b>5.4</b> Comparación de dendogramas</a></li>
<li class="chapter" data-level="5.5" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#heatmaps"><i class="fa fa-check"></i><b>5.5</b> Heatmaps</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html"><i class="fa fa-check"></i><b>6</b> Evaluación de clusters</a>
<ul>
<li class="chapter" data-level="6.1" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#tendencia-de-factibilidad"><i class="fa fa-check"></i><b>6.1</b> Tendencia de factibilidad</a></li>
<li class="chapter" data-level="6.2" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#medidas-internas-de-ajuste"><i class="fa fa-check"></i><b>6.2</b> Medidas internas de ajuste</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#inercia-1"><i class="fa fa-check"></i><b>6.2.1</b> Inercia</a></li>
<li class="chapter" data-level="6.2.2" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#silhouette-1"><i class="fa fa-check"></i><b>6.2.2</b> Silhouette</a></li>
<li class="chapter" data-level="6.2.3" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#índice-de-dunn"><i class="fa fa-check"></i><b>6.2.3</b> Índice de Dunn</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#selección-de-algoritmo"><i class="fa fa-check"></i><b>6.3</b> Selección de algoritmo</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="evaluación-de-clusters.html"><a href="evaluación-de-clusters.html#métricas-para-comparar-algoritmos"><i class="fa fa-check"></i><b>6.3.1</b> Métricas para comparar algoritmos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html"><i class="fa fa-check"></i><b>7</b> Anexo: Visualización con Ggplot</a>
<ul>
<li class="chapter" data-level="7.1" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#ggplot2"><i class="fa fa-check"></i><b>7.1</b> Ggplot2</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#objetos-aesteticos"><i class="fa fa-check"></i><b>7.1.1</b> Objetos aesteticos</a></li>
<li class="chapter" data-level="7.1.2" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#objetos-geométricos-o-capas"><i class="fa fa-check"></i><b>7.1.2</b> Objetos geométricos o capas</a></li>
<li class="chapter" data-level="7.1.3" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#facetas"><i class="fa fa-check"></i><b>7.1.3</b> Facetas</a></li>
<li class="chapter" data-level="7.1.4" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#más-sobre-estéticas"><i class="fa fa-check"></i><b>7.1.4</b> Más sobre estéticas</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#referencias"><i class="fa fa-check"></i><b>7.2</b> Referencias</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AMAT- Ciencia de Datos y Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="análisis-de-componentes-principales" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Capítulo 3</span> Análisis de Componentes Principales<a href="análisis-de-componentes-principales.html#análisis-de-componentes-principales" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>El análisis PCA (por sus siglas en inglés) es una <strong>técnica de reducción de dimensión</strong> útil tanto para el proceso de análisis exploratorio, el inferencial y predictivo. Es una técnica ampliamente usada en muchos estudios, pues permite sintetizar la información relevante y desechar aquello que no aporta tanto. Es particularmente útil en el caso de conjuntos de datos “amplios” en donde las <strong>variables están correlacionadas entre sí</strong> y donde se tienen muchas variables para cada observación.</p>
<p><img src="img/02-pca/dimension_reduction.jpeg" width="600pt" height="400pt" style="display: block; margin: auto;" /></p>
<p>En los conjuntos de datos donde hay muchas variables presentes, no es fácil trazar los datos en su formato original, lo que dificulta tener una idea de las tendencias presentes en ellos. PCA permite ver la estructura general de los datos, identificando qué observaciones son similares entre sí y cuáles son diferentes. Esto puede permitirnos identificar grupos de muestras que son similares y determinar qué variables hacen a un grupo diferente de otro.</p>
<div id="medidas-de-dispersión" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Medidas de dispersión<a href="análisis-de-componentes-principales.html#medidas-de-dispersión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las medidas de dispersión tratan, a través del cálculo de diferentes fórmulas, de arrojar un valor numérico que ofrezca información sobre el grado de variabilidad de una característica</p>
<p>En otras palabras, las medidas de dispersión son números que indican si una variable se mueve mucho, poco, más o menos que otra. La razón de ser de este tipo de medidas es conocer de manera resumida una característica de la variable estudiada. En este sentido, deben acompañar a las medidas de tendencia central. Juntas, ofrecen información de un sólo vistazo que luego podremos utilizar para comparar y, si fuera preciso, tomar decisiones.</p>
<p>Dos de las medidas principales son la <strong>varianza</strong> también denotada como <span class="math inline">\(\sigma^2\)</span> y la <strong>desviación estándar</strong> <span class="math inline">\(\sigma\)</span>.</p>
<p>La <em>varianza</em> es una medida de dispersión que representa la variabilidad de una serie de datos respecto a su media y la <strong>desviación estándar</strong> es la separación que existe entre un valor cualquiera de la serie y la media.</p>
<div id="ejemplo" class="section level4 unnumbered hasAnchor">
<h4>Ejemplo:<a href="análisis-de-componentes-principales.html#ejemplo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Tú y tus amigos han medido las alturas de sus perros (en milímetros):</p>
<p><img src="img/02-pca/Varianza1.jpeg" width="500pt" style="display: block; margin: auto;" /></p>
<p>Las alturas (hasta el lomo de cada perro) son: 600mm, 470mm, 170mm, 430mm y 300mm.
Si calculamos la media, sería:</p>
<p><span class="math display">\[ Media = \frac{1}{n}\sum_{i=1}^{n}{x_i} = \frac{600 + 470 + 170 + 430 + 300}{5} = 394 \]</span></p>
<p>así que la altura media es 394 mm. Si se dibuja esto en el gráfico:</p>
<p><img src="img/02-pca/Varianza2.jpeg" width="500pt" style="display: block; margin: auto;" /></p>
<p>Si ahora se calcula la diferencia de cada altura con la media:</p>
<p><img src="img/02-pca/Varianza3.jpeg" width="500pt" style="display: block; margin: auto;" /></p>
<p>Para calcular la <strong>Varianza</strong>, se toma cada diferencia, se eleva al cuadrado y se calcula la media:</p>
<p><span class="math display">\[ Varianza = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2 = \frac{206^2 + 76^2 + (−224)^2 + 36^2 + (−94)^2}{5} = 21,704\]</span></p>
<p>Por otro lado, la <strong>desviación estándar</strong> se calcula como la raíz cuadrada de la varianza, entonces:</p>
<p><span class="math display">\[\sigma = \sqrt{\sigma^2}  =   \sqrt{21704} = \pm 147 \]</span></p>
<p>Si se dibuja esta distancia, ahora se pueden ver qué alturas están dentro de una desviación estándar (147mm) de la media:</p>
<p><img src="img/02-pca/Varianza4.jpeg" width="500pt" style="display: block; margin: auto;" /></p>
<p>Por lo tanto, usando la desviación estándar tenemos una manera “estándar” de saber qué es normal, o extra grande o extra pequeño.</p>
<p>Los Rottweilers son perros grandes. Y los Dachsunds (perro salchicha) son un poco pequeños, ¿cierto?</p>
<p>La tercera medida que se revisará es el <strong>coeficiente de correlación lineal</strong> (<span class="math inline">\(\rho\)</span>) que es también solo llamada <strong>“correlación”</strong> es una medida de regresión que pretende cuantificar el grado de variación conjunta entre dos variables.</p>
<p>Dicha medida puede encontrarse entre -1 y 1, donde se pueden tener las siguientes interpretaciones dependiendo de su valor:</p>
<p><img src="img/02-pca/correlacion.jpeg" width="500pt" style="display: block; margin: auto;" /></p>
<p>En pocas palabras, mide qué tanto varía una característica en la medida en que varía otra. La fórmula para calcular el grado de correlación es:</p>
<p><span class="math display">\[Cor(x, y) = \frac{\sum_{i=1}^n{(x_i-\bar{x})(y_i-\bar{y})}}{\sqrt{\sum(x_i-\bar{x})^2}\sqrt{\sum(y_i-\bar{y})^2}}\]</span></p>
</div>
</div>
<div id="construcción-matemática" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Construcción matemática<a href="análisis-de-componentes-principales.html#construcción-matemática" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sea <span class="math inline">\(X\)</span> una matriz de <span class="math inline">\(n\)</span> renglones y <span class="math inline">\(p\)</span> columnas, se denota por <span class="math inline">\(X_i\)</span> a la <em>i-ésima</em> columna que representa una característica del conjunto en su totalidad…</p>
<ul>
<li>Se desean crear nuevas variables llamadas <strong>Componentes Principales</strong>, las cuales son creadas como combinación lineal (suma ponderada) de las variables originales, por lo que cada una de las variables nuevas contiene parcialmente información de todas las variables originales.</li>
</ul>
<p><span class="math display">\[Z_1 = a_{11}X_1 +a_{12}X_2 + ... + a_{1p}X_p\]</span>
<span class="math display">\[Z_2 = a_{21}X_1 +a_{22}X_2 + ... + a_{2p}X_p\]</span>
<span class="math display">\[...\]</span>
<span class="math display">\[Z_p = a_{p1}X_1 +a_{p2}X_2 + ... + a_{pp}X_p\]</span></p>
<p>Donde:</p>
<blockquote>
<p><span class="math inline">\(Z_i\)</span> es la iésima componente nueva creada como combinación de las características originales</p>
<p><span class="math inline">\(X_1, X_2, ... X_p\)</span> son las columnas (variables originales)</p>
<p><span class="math inline">\(a_{ij}\)</span> es el peso o aportación de cada columna <em>j</em> a la nueva componente <em>i</em>.</p>
</blockquote>
<ul>
<li>Se desea que la primer componente principal capture la mayor varianza posible de todo el conjunto de datos.</li>
</ul>
<p><span class="math display">\[\forall i \in 2,...,p \quad Var(Z_1)&gt;Var(Z_i)\]</span></p>
<ul>
<li>La segunda componente principal deberá <strong>SER INDEPENDIENTE</strong> de la primera y deberá abarcar la mayor varianza posible del restante. Esta condición se debe cumplir para toda componente <em>i</em>, de tal forma que las nuevas componentes creadas son independientes entre sí y acumulan la mayor proporción de varianza en las primeras de ellas, dejando la mínima proporción de varianza a las últimas componentes.</li>
</ul>
<p><span class="math display">\[Z_1 \perp\!\!\!\perp Z_2 \quad \&amp; \quad Var(Z_1)&gt;Var(Z_2)&gt;Var(Z_i)\]</span></p>
<ul>
<li>El punto anterior permite desechar unas cuantas componentes (las últimas) sin perder mucha varianza.</li>
</ul>
<div class="infobox note">
<p><strong>¡¡ RECORDAR !!</strong></p>
<ul>
<li><p><strong>A través de CPA se logra retener la mayor cantidad de varianza útil pero usando menos componentes que el número de variables originales.</strong></p></li>
<li><p><strong>Para que este proceso sea efectivo, debe existir ALTA correlación entre las variables originales.</strong></p></li>
</ul>
</div>
<p>Cuando muchas variables se correlacionan entre sí, todas contribuirán fuertemente al mismo componente principal. Cada componente principal suma un cierto porcentaje de la variación total en el conjunto de datos. Cuando sus variables iniciales estén fuertemente correlacionadas entre sí y podrá aproximar la mayor parte de la complejidad de su conjunto de datos con solo unos pocos componentes principales.</p>
<p>Agregar componentes adicionales hace que la estimación del conjunto de datos total sea más precisa, pero también más difícil de manejar.</p>
<div id="eigenvalores-y-eigenvectores" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Eigenvalores y eigenvectores<a href="análisis-de-componentes-principales.html#eigenvalores-y-eigenvectores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estimar la ponderación adecuada que debe tener cada una de características para crear las nuevas componentes es un paso crucial en este análisis. Se puede demostrar bajo una rigurosa metodología matemática que la solución que permite obtener resultados óptimos se logra cuando:</p>
<p><span class="math display">\[Xv=\lambda v\]</span>
Donde:</p>
<blockquote>
<p><span class="math inline">\(X\)</span> es la matriz de correlación calculada a partir de los datos originales</p>
<p><span class="math inline">\(v\)</span> es el vector con los pesos de cada columna (eigenvector).</p>
<p><span class="math inline">\(\lambda\)</span> corresponde a la varianza de cada nueva componente (eigenvalor).</p>
</blockquote>
<p>Este resultado corresponde al cálculo de los <em>eigenvectores</em> <span class="math inline">\(v\)</span> (vectores propios) y eigenvalores <span class="math inline">\(\lambda\)</span> (valores propios) de una matriz de datos.</p>
<p>Los vectores propios y los valores propios vienen en pares: <strong>cada vector propio tiene un valor propio correspondiente</strong>. Los vectores propios son la ponderación que permite crear la combinación lineal de las variables para conformar cada componente principal, mientras que el valor propio es la varianza asociada a cada componente principal.</p>
<div class="infobox pin">
<ul>
<li><p>El valor propio de una componente es la varianza de este.</p></li>
<li><p>La suma acumulada de los primeros <span class="math inline">\(j\)</span> eigenvalores representa la varianza acumulada de las primeras <span class="math inline">\(j\)</span> componentes principales</p></li>
</ul>
</div>
<p>El número de valores propios y vectores propios que existe es igual al número de dimensiones que tiene el conjunto de datos.</p>
<p>Para una mayor explicación matemática, este <a href="https://www.amazon.com/Methods-Multivariate-Analysis-Alvin-Rencher/dp/0470178965">libro</a> ofrece un amplio capítulo dedicado exclusivamente al análisis de componentes principales</p>
</div>
</div>
<div id="implementación-en-r" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Implementación en R<a href="análisis-de-componentes-principales.html#implementación-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para ejemplificar el uso de CPA, usaremos los <a href="https://drive.google.com/file/d/1eMBDMxtbRel4BQ0RqMnuwGr-nGNzshgc/view?usp=sharing">datos</a> de CONAPO para replicar el índice de marginación social, el cual pretende dar una medida de pobreza por regiones, las cuales pueden ser entidades, municipios, localidades, agebs o incluso manzanas*.</p>
<p>Existen MUUUCHAS librerías que facilitan el análisis de componentes principales. En este <a href="https://aedin.github.io/PCAworkshop/articles/b_PCA.html">blog</a> se puede encontrar la diferencia en su implementación. Todas ofrecen resultados útiles y confiables.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="análisis-de-componentes-principales.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb2-2"><a href="análisis-de-componentes-principales.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb2-3"><a href="análisis-de-componentes-principales.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb2-4"><a href="análisis-de-componentes-principales.html#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="análisis-de-componentes-principales.html#cb2-5" aria-hidden="true" tabindex="-1"></a>indice_marg <span class="ot">&lt;-</span> <span class="fu">st_read</span>(<span class="st">&#39;data/IMEF_2010.dbf&#39;</span>, <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-6"><a href="análisis-de-componentes-principales.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(indice_marg)</span></code></pre></div>
<pre><code>## Rows: 32
## Columns: 16
## $ CVE_ENT &lt;chr&gt; &quot;01&quot;, &quot;02&quot;, &quot;03&quot;, &quot;04&quot;, &quot;05&quot;, &quot;06&quot;, &quot;07&quot;, &quot;08&quot;, &quot;09&quot;, &quot;10&quot;, &quot;1…
## $ AÑO     &lt;int&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…
## $ POB_TOT &lt;int&gt; 1184996, 3155070, 637026, 822441, 2748391, 650555, 4796580, 34…
## $ ANALF   &lt;dbl&gt; 3.274040, 2.600783, 3.234464, 8.370643, 2.645050, 5.157943, 17…
## $ SPRIM   &lt;dbl&gt; 14.754823, 12.987567, 14.273833, 22.541207, 12.168029, 18.4761…
## $ OVSDE   &lt;dbl&gt; 1.0649743, 0.4322072, 0.9436751, 6.4196750, 1.0916308, 0.68577…
## $ OVSEE   &lt;dbl&gt; 0.62347891, 0.94517891, 2.84464884, 2.59080046, 0.53707721, 0.…
## $ OVSAE   &lt;dbl&gt; 0.9854257, 3.5616214, 7.0865085, 9.7378176, 1.3908497, 1.17060…
## $ VHAC    &lt;dbl&gt; 30.33066, 29.05839, 31.73806, 45.96720, 30.26891, 31.32052, 53…
## $ OVPT    &lt;dbl&gt; 1.761813, 3.398537, 5.814081, 4.500699, 1.423701, 4.691477, 15…
## $ PL_5000 &lt;dbl&gt; 25.1626166, 10.3491523, 15.6188287, 30.8755279, 12.1486353, 14…
## $ PO2SM   &lt;dbl&gt; 33.64880, 21.86970, 23.29986, 45.51076, 30.04270, 32.04402, 69…
## $ IM      &lt;dbl&gt; -0.91086057, -1.14014880, -0.68128749, 0.43357139, -1.14000448…
## $ GM      &lt;chr&gt; &quot;Bajo&quot;, &quot;Muy bajo&quot;, &quot;Bajo&quot;, &quot;Alto&quot;, &quot;Muy bajo&quot;, &quot;Bajo&quot;, &quot;Muy a…
## $ LUGAR   &lt;int&gt; 28, 30, 23, 10, 29, 26, 2, 21, 32, 15, 14, 1, 6, 27, 22, 8, 19…
## $ NOM_ENT &lt;chr&gt; &quot;Aguascalientes&quot;, &quot;Baja California&quot;, &quot;Baja California Sur&quot;, &quot;C…</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="análisis-de-componentes-principales.html#cb4-1" aria-hidden="true" tabindex="-1"></a>indice_marg <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">count</span>(GM, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##         GM n
## 1    Medio 9
## 2     Alto 8
## 3     Bajo 8
## 4 Muy bajo 4
## 5 Muy alto 3</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="análisis-de-componentes-principales.html#cb6-1" aria-hidden="true" tabindex="-1"></a>pca_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(IM <span class="sc">~</span> ., <span class="at">data =</span> indice_marg) <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="análisis-de-componentes-principales.html#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(NOM_ENT, GM, <span class="at">new_role =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb6-3"><a href="análisis-de-componentes-principales.html#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM) <span class="sc">%&gt;%</span></span>
<span id="cb6-4"><a href="análisis-de-componentes-principales.html#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_pca</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM, <span class="at">num_comp=</span><span class="dv">9</span>, <span class="at">res=</span><span class="st">&quot;res&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb6-5"><a href="análisis-de-componentes-principales.html#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rm</span>(LUGAR, AÑO, POB_TOT) <span class="sc">%&gt;%</span> </span>
<span id="cb6-6"><a href="análisis-de-componentes-principales.html#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb6-7"><a href="análisis-de-componentes-principales.html#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="análisis-de-componentes-principales.html#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="fu">juice</span>(pca_recipe)</span></code></pre></div>
<pre><code>## # A tibble: 32 × 13
##    CVE_ENT GM     NOM_ENT      IM    PC1     PC2     PC3     PC4     PC5     PC6
##    &lt;fct&gt;   &lt;fct&gt;  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1 01      Bajo   Aguasc… -0.911  -2.34  -0.227   0.372   0.492   0.264   0.0764
##  2 02      Muy b… Baja C… -1.14   -2.93   0.595  -0.0597 -0.492   0.291  -0.0508
##  3 03      Bajo   Baja C… -0.681  -1.75   1.37   -0.683  -0.400  -0.304   0.160 
##  4 04      Alto   Campec…  0.434   1.12  -0.819  -0.151  -0.271  -0.929   0.178 
##  5 05      Muy b… Coahui… -1.14   -2.93  -0.144   0.157  -0.133   0.0419 -0.0786
##  6 06      Bajo   Colima  -0.779  -2.00   0.0316  0.552  -0.136   0.320  -0.729 
##  7 07      Muy a… Chiapas  2.32    5.96   0.132   1.36   -0.0122 -0.673  -0.471 
##  8 08      Bajo   Chihua… -0.520  -1.34   1.05   -1.27    0.633  -0.646  -0.387 
##  9 09      Muy b… Distri… -1.48   -3.81   0.110   0.159  -0.453   0.205  -0.355 
## 10 10      Medio  Durango  0.0525  0.135  0.675  -1.50    0.929  -0.448   0.146 
## # … with 22 more rows, and 3 more variables: PC7 &lt;dbl&gt;, PC8 &lt;dbl&gt;, PC9 &lt;dbl&gt;</code></pre>
<p>Veamos los pasos de esta receta:</p>
<ul>
<li><p>Primero, debemos decirle a la receta qué datos se usan para predecir la variable de respuesta.</p></li>
<li><p>Se actualiza el rol de las variables <em>nombre de entidad</em> y <em>grado de marginación</em> con la función <code>NOM_ENT</code>, ya que es una variable que queremos mantener por conveniencia como identificador de filas, pero no son un predictor ni variable de respuesta.</p></li>
<li><p>Necesitamos centrar y escalar los predictores numéricos, porque estamos a punto de implementar <strong>PCA</strong>.</p></li>
<li><p>Finalmente, usamos <code>step_pca()</code> para realizar el análisis de componentes principales.</p></li>
<li><p>La función <code>prep()</code> es la que realiza toda la preparación de la receta.</p></li>
</ul>
<p>Una vez que hayamos hecho eso, podremos explorar los resultados del <strong>PCA</strong>. Comencemos por ver cómo resultó el <strong>PCA</strong>. Podemos ordenar los resultados mediante la función <code>tidy()</code>, incluido el paso de <strong>PCA</strong>, que es el segundo paso. Luego hagamos una visualización para ver cómo se ven los componentes.</p>
<p>A continuación se muestran la desviación estándar, porcentaje de varianza y porcentaje de varianza acumulada que aporta cada componente principal.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="análisis-de-componentes-principales.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pca_recipe<span class="sc">$</span>steps[[<span class="dv">2</span>]]<span class="sc">$</span>res)</span></code></pre></div>
<pre><code>## Importance of components:
##                          PC1     PC2    PC3     PC4     PC5     PC6     PC7
## Standard deviation     2.572 0.82085 0.7920 0.64640 0.52101 0.44069 0.31797
## Proportion of Variance 0.735 0.07487 0.0697 0.04643 0.03016 0.02158 0.01123
## Cumulative Proportion  0.735 0.80990 0.8796 0.92603 0.95619 0.97777 0.98900
##                            PC8     PC9
## Standard deviation     0.25660 0.18201
## Proportion of Variance 0.00732 0.00368
## Cumulative Proportion  0.99632 1.00000</code></pre>
<p>Podemos observar que en la primera componente principal, las <span class="math inline">\(9\)</span> variables que utilizó el Consejo Nacional de Población para obtener el <a href="http://www.conapo.gob.mx/work/models/CONAPO/Resource/862/4/images/06_C_AGEB.pdf">Índice de Marginación 2010</a> aportan de manera positiva en el primer componente principal.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="análisis-de-componentes-principales.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb10-2"><a href="análisis-de-componentes-principales.html#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="análisis-de-componentes-principales.html#cb10-3" aria-hidden="true" tabindex="-1"></a>tidied_pca <span class="ot">&lt;-</span> <span class="fu">tidy</span>(pca_recipe, <span class="dv">2</span>)</span>
<span id="cb10-4"><a href="análisis-de-componentes-principales.html#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="análisis-de-componentes-principales.html#cb10-5" aria-hidden="true" tabindex="-1"></a>tidied_pca <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="análisis-de-componentes-principales.html#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(component <span class="sc">%in%</span> <span class="fu">paste0</span>(<span class="st">&quot;PC&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb10-7"><a href="análisis-de-componentes-principales.html#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(component) <span class="sc">%&gt;%</span></span>
<span id="cb10-8"><a href="análisis-de-componentes-principales.html#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">top_n</span>(<span class="dv">9</span>, <span class="fu">abs</span>(value)) <span class="sc">%&gt;%</span></span>
<span id="cb10-9"><a href="análisis-de-componentes-principales.html#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb10-10"><a href="análisis-de-componentes-principales.html#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">terms =</span> <span class="fu">reorder_within</span>(terms, <span class="fu">abs</span>(value), component)) <span class="sc">%&gt;%</span></span>
<span id="cb10-11"><a href="análisis-de-componentes-principales.html#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="fu">abs</span>(value), terms, <span class="at">fill =</span> value <span class="sc">&gt;</span> <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb10-12"><a href="análisis-de-componentes-principales.html#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb10-13"><a href="análisis-de-componentes-principales.html#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>component, <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="sc">+</span></span>
<span id="cb10-14"><a href="análisis-de-componentes-principales.html#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_reordered</span>() <span class="sc">+</span></span>
<span id="cb10-15"><a href="análisis-de-componentes-principales.html#cb10-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb10-16"><a href="análisis-de-componentes-principales.html#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Absolute value of contribution&quot;</span>,</span>
<span id="cb10-17"><a href="análisis-de-componentes-principales.html#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="cn">NULL</span>, <span class="at">fill =</span> <span class="st">&quot;Positive?&quot;</span></span>
<span id="cb10-18"><a href="análisis-de-componentes-principales.html#cb10-18" aria-hidden="true" tabindex="-1"></a>  )<span class="sc">+</span></span>
<span id="cb10-19"><a href="análisis-de-componentes-principales.html#cb10-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>Notamos que las <span class="math inline">\(9\)</span> variables aportan entre el <span class="math inline">\(25\%\)</span> y el <span class="math inline">\(35\%\)</span> a la
primera componente principal.</p>
</div>
<div id="reducción-de-dimensión" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Reducción de dimensión<a href="análisis-de-componentes-principales.html#reducción-de-dimensión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Existe en la literatura basta información sobre el número de componentes a retener en un análisis de PCA. El siguiente gráfico lleva por nombre <strong>gráfico de codo</strong> y muestra el porcentaje de varianza explicado por cada componente principal.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="análisis-de-componentes-principales.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb11-2"><a href="análisis-de-componentes-principales.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(FactoMineR)</span>
<span id="cb11-3"><a href="análisis-de-componentes-principales.html#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="análisis-de-componentes-principales.html#cb11-4" aria-hidden="true" tabindex="-1"></a>res.pca <span class="ot">&lt;-</span> indice_marg <span class="sc">%&gt;%</span></span>
<span id="cb11-5"><a href="análisis-de-componentes-principales.html#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM) <span class="sc">%&gt;%</span> </span>
<span id="cb11-6"><a href="análisis-de-componentes-principales.html#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb11-7"><a href="análisis-de-componentes-principales.html#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_rownames</span>(indice_marg<span class="sc">$</span>NOM_ENT) <span class="sc">%&gt;%</span> </span>
<span id="cb11-8"><a href="análisis-de-componentes-principales.html#cb11-8" aria-hidden="true" tabindex="-1"></a>  FactoMineR<span class="sc">::</span><span class="fu">PCA</span>(<span class="at">graph=</span><span class="cn">FALSE</span>)</span>
<span id="cb11-9"><a href="análisis-de-componentes-principales.html#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="análisis-de-componentes-principales.html#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_eig</span>(res.pca, <span class="at">addlabels=</span><span class="cn">TRUE</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">100</span>))</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>El gráfico anterior muestra que hay una diferencia muy grande entre la varianza retenida por la 1er componente principal y el resto de las variables. Dependiendo del objetivo del análisis, podrá elegirse el numero adecuado de componentes a retener, no obstante, la literatura sugiere retener 1 o 2 componentes principales.</p>
<p>Es posible realizar el proceso de componentes principales y elegir una de las dos opciones siguientes:</p>
<ol style="list-style-type: decimal">
<li><p>Especificar el número de componentes a retener</p></li>
<li><p>Indicar el porcentaje de varianza a alcanzar</p></li>
</ol>
<p>La segunda opción elegirá tantas componentes como sean necesarias hasta alcanzar el hiperparámetro mínimo indicado. A continuación se ejemplifica:</p>
<p><strong>Caso 1:</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="análisis-de-componentes-principales.html#cb12-1" aria-hidden="true" tabindex="-1"></a>pca_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(IM <span class="sc">~</span> ., <span class="at">data =</span> indice_marg) <span class="sc">%&gt;%</span></span>
<span id="cb12-2"><a href="análisis-de-componentes-principales.html#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(NOM_ENT, GM, <span class="at">new_role =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-3"><a href="análisis-de-componentes-principales.html#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM) <span class="sc">%&gt;%</span></span>
<span id="cb12-4"><a href="análisis-de-componentes-principales.html#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_pca</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM,<span class="at">num_comp=</span><span class="dv">2</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-5"><a href="análisis-de-componentes-principales.html#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rm</span>(LUGAR, AÑO, POB_TOT) <span class="sc">%&gt;%</span> </span>
<span id="cb12-6"><a href="análisis-de-componentes-principales.html#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb12-7"><a href="análisis-de-componentes-principales.html#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="análisis-de-componentes-principales.html#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="fu">juice</span>(pca_recipe)</span></code></pre></div>
<pre><code>## # A tibble: 32 × 6
##    CVE_ENT GM       NOM_ENT                   IM    PC1     PC2
##    &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;                  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1 01      Bajo     Aguascalientes       -0.911  -2.34  -0.227 
##  2 02      Muy bajo Baja California      -1.14   -2.93   0.595 
##  3 03      Bajo     Baja California Sur  -0.681  -1.75   1.37  
##  4 04      Alto     Campeche              0.434   1.12  -0.819 
##  5 05      Muy bajo Coahuila de Zaragoza -1.14   -2.93  -0.144 
##  6 06      Bajo     Colima               -0.779  -2.00   0.0316
##  7 07      Muy alto Chiapas               2.32    5.96   0.132 
##  8 08      Bajo     Chihuahua            -0.520  -1.34   1.05  
##  9 09      Muy bajo Distrito Federal     -1.48   -3.81   0.110 
## 10 10      Medio    Durango               0.0525  0.135  0.675 
## # … with 22 more rows</code></pre>
<p><strong>Caso 2:</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="análisis-de-componentes-principales.html#cb14-1" aria-hidden="true" tabindex="-1"></a>pca_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(IM <span class="sc">~</span> ., <span class="at">data =</span> indice_marg) <span class="sc">%&gt;%</span></span>
<span id="cb14-2"><a href="análisis-de-componentes-principales.html#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(NOM_ENT, GM, <span class="at">new_role =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb14-3"><a href="análisis-de-componentes-principales.html#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM) <span class="sc">%&gt;%</span></span>
<span id="cb14-4"><a href="análisis-de-componentes-principales.html#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_pca</span>(ANALF, SPRIM, OVSDE, OVSEE, OVSAE, VHAC, OVPT, PL_5000, PO2SM,<span class="at">threshold=</span><span class="fl">0.90</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb14-5"><a href="análisis-de-componentes-principales.html#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rm</span>(LUGAR, AÑO, POB_TOT) <span class="sc">%&gt;%</span> </span>
<span id="cb14-6"><a href="análisis-de-componentes-principales.html#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb14-7"><a href="análisis-de-componentes-principales.html#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="análisis-de-componentes-principales.html#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="fu">juice</span>(pca_recipe)</span></code></pre></div>
<pre><code>## # A tibble: 32 × 8
##    CVE_ENT GM       NOM_ENT                   IM    PC1     PC2     PC3     PC4
##    &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;                  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1 01      Bajo     Aguascalientes       -0.911  -2.34  -0.227   0.372   0.492 
##  2 02      Muy bajo Baja California      -1.14   -2.93   0.595  -0.0597 -0.492 
##  3 03      Bajo     Baja California Sur  -0.681  -1.75   1.37   -0.683  -0.400 
##  4 04      Alto     Campeche              0.434   1.12  -0.819  -0.151  -0.271 
##  5 05      Muy bajo Coahuila de Zaragoza -1.14   -2.93  -0.144   0.157  -0.133 
##  6 06      Bajo     Colima               -0.779  -2.00   0.0316  0.552  -0.136 
##  7 07      Muy alto Chiapas               2.32    5.96   0.132   1.36   -0.0122
##  8 08      Bajo     Chihuahua            -0.520  -1.34   1.05   -1.27    0.633 
##  9 09      Muy bajo Distrito Federal     -1.48   -3.81   0.110   0.159  -0.453 
## 10 10      Medio    Durango               0.0525  0.135  0.675  -1.50    0.929 
## # … with 22 more rows</code></pre>
<p>Así es como usaremos el análisis de componentes principales para mejorar la estructura de variables que sirven de input para cualquiera de los modelos posteriores. Continuaremos con un paso más de pre-procesamiento antes de comenzar a aprender nuevos modelos.</p>
</div>
<div id="representación-gráfica" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Representación gráfica<a href="análisis-de-componentes-principales.html#representación-gráfica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Uno de los gráficos más famosos al usar CPA es el Biplot, el cual busca representar en dos dimensiones el comportamiento y grado de asociación tanto entre las variables como las observaciones</p>
<p>El siguiente biplot permite analizar en dos dimensiones la relación entre variables</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="análisis-de-componentes-principales.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_pca_var</span>(</span>
<span id="cb16-2"><a href="análisis-de-componentes-principales.html#cb16-2" aria-hidden="true" tabindex="-1"></a>  res.pca,</span>
<span id="cb16-3"><a href="análisis-de-componentes-principales.html#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.var =</span> <span class="st">&quot;contrib&quot;</span>, <span class="co"># Color by contributions to the PC</span></span>
<span id="cb16-4"><a href="análisis-de-componentes-principales.html#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">gradient.cols =</span> <span class="fu">c</span>(<span class="st">&quot;#00AFBB&quot;</span>, <span class="st">&quot;#E7B800&quot;</span>, <span class="st">&quot;#FC4E07&quot;</span>),</span>
<span id="cb16-5"><a href="análisis-de-componentes-principales.html#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">repel =</span> <span class="cn">TRUE</span>     <span class="co"># Avoid text overlapping</span></span>
<span id="cb16-6"><a href="análisis-de-componentes-principales.html#cb16-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<p>En este gráfico se logra apreciar que todas las características están asociadas a la misma dirección en relación con la primer componente principal, mientras que en la segunda componente existe un poco de diferencia.</p>
<p>Entre más pequeño sea el ángulo que separa a dos vectores, mayor correlación existe entre las características. Adicionalmente, si el grado es cercano a los 180°, esto representa una perfecta correlación negativa. Por último, grados cercanos a los 90° ocurren cuando las variables son independientes.</p>
<p>Entre más larga es la longitud de cada vector, esto representa mayor varianza en la característica que se está observando.</p>
<p>A continuación, se muestra otra versión del biplot en donde se analizan tanto las variables como las observaciones</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="análisis-de-componentes-principales.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_pca_biplot</span>(</span>
<span id="cb17-2"><a href="análisis-de-componentes-principales.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  res.pca, <span class="at">repel =</span> <span class="cn">TRUE</span>,</span>
<span id="cb17-3"><a href="análisis-de-componentes-principales.html#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.var =</span> <span class="st">&quot;#2E9FDF&quot;</span>, <span class="co"># Variables color</span></span>
<span id="cb17-4"><a href="análisis-de-componentes-principales.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.ind =</span> <span class="st">&quot;#696969&quot;</span>  <span class="co"># Individuals color</span></span>
<span id="cb17-5"><a href="análisis-de-componentes-principales.html#cb17-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>La proyección ortogonal de cada punto en un vector permite conocer el grado positivo o negativo de una observación en relación con cada una de las variables. Por ejemplo…</p>
<ol style="list-style-type: decimal">
<li><p>La proyección del Distrito Federal con cada una de las variables se encuentra en la dirección negativa, lo que implica que la relación de esta entidad con las variables que miden pobreza es negativa.</p></li>
<li><p>En el caso de Oaxaca, la relación es positiva, lo que implica que Oaxaca tiene una marginación alta.</p></li>
</ol>
<p>A partir de estas gráficas, se logran realizar simplificaciones o variaciones de gráficas para estudiar posibles agrupaciones, como se muestra en el siguiente gráfico.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="análisis-de-componentes-principales.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggrepel)</span>
<span id="cb18-2"><a href="análisis-de-componentes-principales.html#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="análisis-de-componentes-principales.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">juice</span>(pca_recipe) <span class="sc">%&gt;%</span></span>
<span id="cb18-4"><a href="análisis-de-componentes-principales.html#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">GM =</span> <span class="fu">factor</span>(GM, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Muy alto&quot;</span>, <span class="st">&quot;Alto&quot;</span>, <span class="st">&quot;Medio&quot;</span>, <span class="st">&quot;Bajo&quot;</span>, <span class="st">&quot;Muy bajo&quot;</span>)), </span>
<span id="cb18-5"><a href="análisis-de-componentes-principales.html#cb18-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">ordered =</span> T) <span class="sc">%&gt;%</span> </span>
<span id="cb18-6"><a href="análisis-de-componentes-principales.html#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(PC1, PC2, <span class="at">label =</span> NOM_ENT)) <span class="sc">+</span></span>
<span id="cb18-7"><a href="análisis-de-componentes-principales.html#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> GM), <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb18-8"><a href="análisis-de-componentes-principales.html#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text_repel</span>() <span class="sc">+</span></span>
<span id="cb18-9"><a href="análisis-de-componentes-principales.html#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Grado de marginación de entidades&quot;</span>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>Finalmente, podemos observar como (de izquierda a derecha) los estados con grado de marginación Muy bajo, Bajo, Medio, Alto y Muy Alto respectivamente.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="análisis-de-componentes-principales.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">juice</span>(pca_recipe) <span class="sc">%&gt;%</span> </span>
<span id="cb19-2"><a href="análisis-de-componentes-principales.html#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> IM, <span class="at">y =</span> PC1)) <span class="sc">+</span></span>
<span id="cb19-3"><a href="análisis-de-componentes-principales.html#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb19-4"><a href="análisis-de-componentes-principales.html#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb19-5"><a href="análisis-de-componentes-principales.html#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Comparación: Índice Marginación Vs PCA CP1&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
</div>
<div id="predicciones" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Predicciones<a href="análisis-de-componentes-principales.html#predicciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Es bastante común que sea necesario ajustar o crear un análisis de componentes con la información disponible hasta cierto momento y posteriormente, nuevas observaciones son incorporadas al estudio. Sería incorrecto volver a crear el análisis cada vez que una observación nueva llega.</p>
<p>Otro escenario de interés se da cuando se tiene muchísima información (millones de datos) y resulta costoso computacionalmente estar creando el modelo usando toda la información.</p>
<p>En ambos escenarios, la solución está en <strong>realizar el análisis de componentes principales con una muestra de los datos y posteriormente realizar la predicción de nuevas observaciones ya teniendo creado el modelo</strong></p>
<p>El siguiente ejemplo contiene datos de atletas y su desempeño en competencias deportivas.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="análisis-de-componentes-principales.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(decathlon2)</span></code></pre></div>
<pre><code>## Rows: 27
## Columns: 13
## $ X100m        &lt;dbl&gt; 11.04, 10.76, 11.02, 11.34, 11.13, 10.83, 11.64, 11.37, 1…
## $ Long.jump    &lt;dbl&gt; 7.58, 7.40, 7.23, 7.09, 7.30, 7.31, 6.81, 7.56, 6.97, 7.2…
## $ Shot.put     &lt;dbl&gt; 14.83, 14.26, 14.25, 15.19, 13.48, 13.76, 14.57, 14.41, 1…
## $ High.jump    &lt;dbl&gt; 2.07, 1.86, 1.92, 2.10, 2.01, 2.13, 1.95, 1.86, 1.95, 1.9…
## $ X400m        &lt;dbl&gt; 49.81, 49.37, 48.93, 50.42, 48.62, 49.91, 50.14, 51.10, 4…
## $ X110m.hurdle &lt;dbl&gt; 14.69, 14.05, 14.99, 15.31, 14.17, 14.38, 14.93, 15.06, 1…
## $ Discus       &lt;dbl&gt; 43.75, 50.72, 40.87, 46.26, 45.67, 44.41, 47.60, 44.99, 4…
## $ Pole.vault   &lt;dbl&gt; 5.02, 4.92, 5.32, 4.72, 4.42, 4.42, 4.92, 4.82, 4.72, 4.6…
## $ Javeline     &lt;dbl&gt; 63.19, 60.15, 62.77, 63.44, 55.37, 56.37, 52.33, 57.19, 5…
## $ X1500m       &lt;dbl&gt; 291.70, 301.50, 280.10, 276.40, 268.00, 285.10, 262.10, 2…
## $ Rank         &lt;int&gt; 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 1, 2, 3, 4, 5, 6, 7,…
## $ Points       &lt;int&gt; 8217, 8122, 8067, 8036, 8004, 7995, 7802, 7733, 7708, 765…
## $ Competition  &lt;fct&gt; Decastar, Decastar, Decastar, Decastar, Decastar, Decasta…</code></pre>
<p>Se eliminarán las últimas 3 columnas para trabajar exclusivamente con las que hacer referencia al desempeño en cada una de las actividades deportivas.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="análisis-de-componentes-principales.html#cb23-1" aria-hidden="true" tabindex="-1"></a>decathlon2_train <span class="ot">&lt;-</span> decathlon2[<span class="dv">1</span><span class="sc">:</span><span class="dv">23</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb23-2"><a href="análisis-de-componentes-principales.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(decathlon2_train)</span></code></pre></div>
<pre><code>## Rows: 23
## Columns: 10
## $ X100m        &lt;dbl&gt; 11.04, 10.76, 11.02, 11.34, 11.13, 10.83, 11.64, 11.37, 1…
## $ Long.jump    &lt;dbl&gt; 7.58, 7.40, 7.23, 7.09, 7.30, 7.31, 6.81, 7.56, 6.97, 7.2…
## $ Shot.put     &lt;dbl&gt; 14.83, 14.26, 14.25, 15.19, 13.48, 13.76, 14.57, 14.41, 1…
## $ High.jump    &lt;dbl&gt; 2.07, 1.86, 1.92, 2.10, 2.01, 2.13, 1.95, 1.86, 1.95, 1.9…
## $ X400m        &lt;dbl&gt; 49.81, 49.37, 48.93, 50.42, 48.62, 49.91, 50.14, 51.10, 4…
## $ X110m.hurdle &lt;dbl&gt; 14.69, 14.05, 14.99, 15.31, 14.17, 14.38, 14.93, 15.06, 1…
## $ Discus       &lt;dbl&gt; 43.75, 50.72, 40.87, 46.26, 45.67, 44.41, 47.60, 44.99, 4…
## $ Pole.vault   &lt;dbl&gt; 5.02, 4.92, 5.32, 4.72, 4.42, 4.42, 4.92, 4.82, 4.72, 4.6…
## $ Javeline     &lt;dbl&gt; 63.19, 60.15, 62.77, 63.44, 55.37, 56.37, 52.33, 57.19, 5…
## $ X1500m       &lt;dbl&gt; 291.70, 301.50, 280.10, 276.40, 268.00, 285.10, 262.10, 2…</code></pre>
<p>En este ejercicio se usará la librería <em>stats</em> y la función <em>prcomp</em> para llevar a cabo el análisis.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="análisis-de-componentes-principales.html#cb25-1" aria-hidden="true" tabindex="-1"></a>res.pca <span class="ot">&lt;-</span> stats<span class="sc">::</span><span class="fu">prcomp</span>(decathlon2_train, <span class="at">scale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-2"><a href="análisis-de-componentes-principales.html#cb25-2" aria-hidden="true" tabindex="-1"></a>res.pca</span></code></pre></div>
<pre><code>## Standard deviations (1, .., p=10):
##  [1] 2.0308159 1.3559244 1.1131668 0.9052294 0.8375875 0.6502944 0.5500742
##  [8] 0.5238988 0.3939758 0.3492435
## 
## Rotation (n x k) = (10 x 10):
##                       PC1         PC2         PC3         PC4        PC5
## X100m        -0.418859080  0.13230683 -0.27089959  0.03708806 -0.2321476
## Long.jump     0.391064807 -0.20713320  0.17117519 -0.12746997  0.2783669
## Shot.put      0.361388111 -0.06298590 -0.46497777  0.14191803 -0.2970589
## High.jump     0.300413236  0.34309742 -0.29652805  0.15968342  0.4807859
## X400m        -0.345478567 -0.21400770 -0.25470839  0.47592968  0.1240569
## X110m.hurdle -0.376265119  0.01824645 -0.40325254 -0.01866477  0.2676975
## Discus        0.365965721 -0.03662510 -0.15857927  0.43636361 -0.4873988
## Pole.vault   -0.106985591 -0.59549862 -0.08449563 -0.37447391 -0.2646712
## Javeline      0.210864329 -0.28475723 -0.54270782 -0.36646463  0.2361698
## X1500m        0.002106782 -0.57855748  0.19715884  0.49491281  0.3142987
##                       PC6         PC7         PC8         PC9        PC10
## X100m         0.054398099 -0.16604375 -0.19988005 -0.76924639  0.12718339
## Long.jump    -0.051865558 -0.28056361 -0.75850657 -0.13094589  0.08509665
## Shot.put     -0.368739186 -0.01797323  0.04649571  0.12129309  0.62263702
## High.jump    -0.437716883  0.05118848  0.16111045 -0.28463225 -0.38244596
## X400m        -0.075796432  0.52012255 -0.44579641  0.20854176 -0.09784197
## X110m.hurdle  0.004048005 -0.67276768 -0.01592804  0.41058421 -0.04475363
## Discus        0.305315353 -0.25946615 -0.07550934  0.03391600 -0.49418361
## Pole.vault   -0.503563524 -0.01889413  0.06282691 -0.06540692 -0.39288155
## Javeline      0.556821016  0.24281145  0.10086127 -0.10268134 -0.01103627
## X1500m        0.064663250 -0.20245828  0.37119711 -0.25950868  0.17991689</code></pre>
<p>Las 10 variables anteriores son las componentes principales creadas a partir de las variables originales. Se puede apreciar en la siguiente línea el impacto que tiene cada componente en términos de varianza.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="análisis-de-componentes-principales.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(res.pca)</span></code></pre></div>
<pre><code>## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5     PC6     PC7
## Standard deviation     2.0308 1.3559 1.1132 0.90523 0.83759 0.65029 0.55007
## Proportion of Variance 0.4124 0.1839 0.1239 0.08194 0.07016 0.04229 0.03026
## Cumulative Proportion  0.4124 0.5963 0.7202 0.80213 0.87229 0.91458 0.94483
##                            PC8     PC9   PC10
## Standard deviation     0.52390 0.39398 0.3492
## Proportion of Variance 0.02745 0.01552 0.0122
## Cumulative Proportion  0.97228 0.98780 1.0000</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="análisis-de-componentes-principales.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_eig</span>(res.pca, <span class="at">addlabels=</span><span class="cn">TRUE</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">100</span>))</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<p>Ahora considérese nuevas observaciones que desean re calculadas usando el análisis de componentes principales. Es indispensable contar con la información de las 10 variables con las que se construyó el modelo.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="análisis-de-componentes-principales.html#cb30-1" aria-hidden="true" tabindex="-1"></a>decathlon2_new <span class="ot">&lt;-</span> decathlon2[<span class="dv">24</span><span class="sc">:</span><span class="dv">27</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb30-2"><a href="análisis-de-componentes-principales.html#cb30-2" aria-hidden="true" tabindex="-1"></a>decathlon2_new[, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code></pre></div>
<pre><code>##         X100m Long.jump Shot.put High.jump X400m X110m.hurdle
## KARPOV  11.02      7.30    14.77      2.04 48.37        14.09
## WARNERS 11.11      7.60    14.31      1.98 48.68        14.23
## Nool    10.80      7.53    14.26      1.88 48.81        14.80
## Drews   10.87      7.38    13.07      1.88 48.51        14.01</code></pre>
<p>Finalmente, se hace uso de la función <em>predict</em> para calcular el valor de las componentes principales en cada uno de los nuevo individuos:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="análisis-de-componentes-principales.html#cb32-1" aria-hidden="true" tabindex="-1"></a>decathlon2_new_coord <span class="ot">&lt;-</span> <span class="fu">predict</span>(res.pca, <span class="at">newdata =</span> decathlon2_new)</span>
<span id="cb32-2"><a href="análisis-de-componentes-principales.html#cb32-2" aria-hidden="true" tabindex="-1"></a>decathlon2_new_coord[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span></code></pre></div>
<pre><code>##                PC1         PC2       PC3        PC4
## KARPOV   0.7772521 -0.76237804 1.5971253  1.6863286
## WARNERS -0.3779697  0.11891968 1.7005146 -0.6908084
## Nool    -0.5468405 -1.93402211 0.4724184 -2.2283706
## Drews   -1.0848227 -0.01703198 2.9818031 -1.5006207</code></pre>
<p>Estos resultados pueden integrarse a las gráficas realizadas para comparar su ubicación en relación con los datos originales usados cuando se creó el modelo.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="análisis-de-componentes-principales.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráfico con observaciones originales en biplot</span></span>
<span id="cb34-2"><a href="análisis-de-componentes-principales.html#cb34-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">fviz_pca_ind</span>(res.pca, <span class="at">repel =</span> <span class="cn">TRUE</span>)</span>
<span id="cb34-3"><a href="análisis-de-componentes-principales.html#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="análisis-de-componentes-principales.html#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Se agregan nuevas observaciones</span></span>
<span id="cb34-5"><a href="análisis-de-componentes-principales.html#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_add</span>(p, decathlon2_new_coord, <span class="at">color =</span><span class="st">&quot;blue&quot;</span>, <span class="at">repel =</span> T)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
</div>
<div id="ejercicios" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Ejercicios<a href="análisis-de-componentes-principales.html#ejercicios" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Observar en una gráfica la contribución de cada variable a las componentes principales y tratar de interpretar las primeras 2 o 3.</p></li>
<li><p>Comparar de manera numérica y gráfica la asociación entre los puntos originales asociados a cada atleta y la primer componente principal</p></li>
</ol>

<div class="watermark">
<img src="img/header.png" width="400">
</div>
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="scoping.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clustering-no-jerárquico.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["amt22_04intro2mlns.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
