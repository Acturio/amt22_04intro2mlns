<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Clustering Jerárquico | AMAT- Ciencia de Datos y Machine Learning</title>
  <meta name="description" content="AMAT: Ciencia de Datos y Machine Learning" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Clustering Jerárquico | AMAT- Ciencia de Datos y Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="AMAT: Ciencia de Datos y Machine Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Clustering Jerárquico | AMAT- Ciencia de Datos y Machine Learning" />
  
  <meta name="twitter:description" content="AMAT: Ciencia de Datos y Machine Learning" />
  

<meta name="author" content="Karina Lizette Gamboa Puente" />
<meta name="author" content="Oscar Arturo Bringas López" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clustering-no-jerárquico.html"/>
<link rel="next" href="anexo-visualización-con-ggplot.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li|
|:-:|  
<center>Ciencia de Datos y Machine Learning</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructores"><i class="fa fa-check"></i>Instructores</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-curso"><i class="fa fa-check"></i>Estructura del curso</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-curso"><i class="fa fa-check"></i>Alcances del curso</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duración-y-evaluación-del-curso"><i class="fa fa-check"></i>Duración y evaluación del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-dinámica-de-clase"><i class="fa fa-check"></i>Recursos y dinámica de clase</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html"><i class="fa fa-check"></i><b>1</b> Introducción a Ciencia de Datos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#qué-es-ciencia-de-datos"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es Ciencia de Datos?</a>
<ul>
<li class="chapter" data-level="" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#definiendo-conceptos"><i class="fa fa-check"></i>Definiendo conceptos:</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#objetivos"><i class="fa fa-check"></i><b>1.2</b> Objetivos</a></li>
<li class="chapter" data-level="1.3" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#requisitos"><i class="fa fa-check"></i><b>1.3</b> Requisitos</a></li>
<li class="chapter" data-level="1.4" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aplicaciones"><i class="fa fa-check"></i><b>1.4</b> Aplicaciones</a></li>
<li class="chapter" data-level="1.5" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#tipos-de-algoritmos"><i class="fa fa-check"></i><b>1.5</b> Tipos de algoritmos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aprendizaje-supervisado"><i class="fa fa-check"></i><b>1.5.1</b> Aprendizaje supervisado</a></li>
<li class="chapter" data-level="1.5.2" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>1.5.2</b> Aprendizaje no supervisado</a></li>
<li class="chapter" data-level="1.5.3" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#aprendizaje-por-refuerzo"><i class="fa fa-check"></i><b>1.5.3</b> Aprendizaje por refuerzo</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introducción-a-ciencia-de-datos.html"><a href="introducción-a-ciencia-de-datos.html#ciclo-de-un-proyecto"><i class="fa fa-check"></i><b>1.6</b> Ciclo de un proyecto</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scoping.html"><a href="scoping.html"><i class="fa fa-check"></i><b>2</b> Scoping</a>
<ul>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#definir-objetivos"><i class="fa fa-check"></i>Definir objetivo(s)</a></li>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#qué-acciones-o-intervenciones-existen-que-serán-mejoradas-a-través-de-este-proyecto"><i class="fa fa-check"></i>¿Qué acciones o intervenciones existen que serán mejoradas a través de este proyecto?</a></li>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#qué-datos-tenemos-y-cuáles-necesitamos"><i class="fa fa-check"></i>¿Qué datos tenemos y cuáles necesitamos?</a></li>
<li class="chapter" data-level="" data-path="scoping.html"><a href="scoping.html#cuál-es-el-análisis-que-necesitamos-hacer"><i class="fa fa-check"></i>¿Cuál es el análisis que necesitamos hacer?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>3</b> Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>3.1</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="3.2" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#construcción-matemática"><i class="fa fa-check"></i><b>3.2</b> Construcción matemática</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#eigenvalores-y-eigenvectores"><i class="fa fa-check"></i><b>3.2.1</b> Eigenvalores y eigenvectores</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#implementación-en-r"><i class="fa fa-check"></i><b>3.3</b> Implementación en R</a></li>
<li class="chapter" data-level="3.4" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#reducción-de-dimensión"><i class="fa fa-check"></i><b>3.4</b> Reducción de dimensión</a></li>
<li class="chapter" data-level="3.5" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>3.5</b> Representación gráfica</a></li>
<li class="chapter" data-level="3.6" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#predicciones"><i class="fa fa-check"></i><b>3.6</b> Predicciones</a></li>
<li class="chapter" data-level="3.7" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#ejercicios"><i class="fa fa-check"></i><b>3.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html"><i class="fa fa-check"></i><b>4</b> Clustering No Jerárquico</a>
<ul>
<li class="chapter" data-level="4.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#cálculo-de-distancia"><i class="fa fa-check"></i><b>4.1</b> Cálculo de distancia</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#distancias-homogéneas"><i class="fa fa-check"></i><b>4.1.1</b> Distancias homogéneas</a></li>
<li class="chapter" data-level="4.1.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#distancias-mixtas"><i class="fa fa-check"></i><b>4.1.2</b> Distancias mixtas</a></li>
<li class="chapter" data-level="4.1.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#visualización-de-distancias"><i class="fa fa-check"></i><b>4.1.3</b> Visualización de distancias</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#k---means"><i class="fa fa-check"></i><b>4.2</b> K - means</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#ajuste-de-modelo-cómo-funciona-el-algortimo"><i class="fa fa-check"></i><b>4.2.1</b> Ajuste de modelo: ¿Cómo funciona el algortimo?</a></li>
<li class="chapter" data-level="4.2.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#calidad-de-ajuste"><i class="fa fa-check"></i><b>4.2.2</b> Calidad de ajuste</a></li>
<li class="chapter" data-level="4.2.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#cómo-seleccionamos-k"><i class="fa fa-check"></i><b>4.2.3</b> ¿Cómo seleccionamos K?</a></li>
<li class="chapter" data-level="4.2.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-1"><i class="fa fa-check"></i><b>4.2.4</b> Implementación en R</a></li>
<li class="chapter" data-level="4.2.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#warnings"><i class="fa fa-check"></i><b>4.2.5</b> Warnings</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#partitioning-around-medoids-pam"><i class="fa fa-check"></i><b>4.3</b> Partitioning Around Medoids (PAM)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#algoritmo-pam"><i class="fa fa-check"></i><b>4.3.1</b> Algoritmo PAM</a></li>
<li class="chapter" data-level="4.3.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-2"><i class="fa fa-check"></i><b>4.3.2</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#clustering-large-applications-clara"><i class="fa fa-check"></i><b>4.4</b> Clustering Large Applications (CLARA)</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-3"><i class="fa fa-check"></i><b>4.4.1</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#dbscan"><i class="fa fa-check"></i><b>4.5</b> DBSCAN</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#algoritmo"><i class="fa fa-check"></i><b>4.5.1</b> Algoritmo</a></li>
<li class="chapter" data-level="4.5.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#estimación-de-parámetros"><i class="fa fa-check"></i><b>4.5.2</b> Estimación de parámetros</a></li>
<li class="chapter" data-level="4.5.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-4"><i class="fa fa-check"></i><b>4.5.3</b> Implementación en R</a></li>
<li class="chapter" data-level="4.5.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#ventajas-de-dbscan"><i class="fa fa-check"></i><b>4.5.4</b> Ventajas de DBSCAN</a></li>
<li class="chapter" data-level="4.5.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#aplicación-dbscan"><i class="fa fa-check"></i><b>4.5.5</b> Aplicación DBSCAN</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#comparación-de-algoritmos"><i class="fa fa-check"></i><b>4.6</b> Comparación de algoritmos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html"><i class="fa fa-check"></i><b>5</b> Clustering Jerárquico</a>
<ul>
<li class="chapter" data-level="5.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#agglomerative-divise-clustering"><i class="fa fa-check"></i><b>5.1</b> Agglomerative &amp; Divise Clustering</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#algoritmo-1"><i class="fa fa-check"></i><b>5.1.1</b> Algoritmo</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#implementación-en-r-5"><i class="fa fa-check"></i><b>5.2</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#preparación-y-estructuración-de-datos"><i class="fa fa-check"></i><b>5.2.1</b> Preparación y estructuración de datos</a></li>
<li class="chapter" data-level="5.2.2" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#medidas-de-disimilaridad"><i class="fa fa-check"></i><b>5.2.2</b> Medidas de (di)similaridad</a></li>
<li class="chapter" data-level="5.2.3" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#función-liga"><i class="fa fa-check"></i><b>5.2.3</b> Función Liga</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#dendogramas"><i class="fa fa-check"></i><b>5.3</b> Dendogramas</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#selección-de-grupos"><i class="fa fa-check"></i><b>5.3.1</b> Selección de grupos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html"><i class="fa fa-check"></i><b>6</b> Anexo: Visualización con Ggplot</a>
<ul>
<li class="chapter" data-level="6.1" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#ggplot2"><i class="fa fa-check"></i><b>6.1</b> Ggplot2</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#objetos-aesteticos"><i class="fa fa-check"></i><b>6.1.1</b> Objetos aesteticos</a></li>
<li class="chapter" data-level="6.1.2" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#objetos-geométricos-o-capas"><i class="fa fa-check"></i><b>6.1.2</b> Objetos geométricos o capas</a></li>
<li class="chapter" data-level="6.1.3" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#facetas"><i class="fa fa-check"></i><b>6.1.3</b> Facetas</a></li>
<li class="chapter" data-level="6.1.4" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#más-sobre-estéticas"><i class="fa fa-check"></i><b>6.1.4</b> Más sobre estéticas</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="anexo-visualización-con-ggplot.html"><a href="anexo-visualización-con-ggplot.html#referencias"><i class="fa fa-check"></i><b>6.2</b> Referencias</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AMAT- Ciencia de Datos y Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering-jerárquico" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Capítulo 5</span> Clustering Jerárquico<a href="clustering-jerárquico.html#clustering-jerárquico" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En esta sección se analizarán diferentes metodologías que tienen como propósito realizar segmentaciones de unidades de manera jerárquica, es decir, a partir de un único grupo se van agrupando o separando los individuos dependiendo de qué tan lejanos o cercanos se encuentran unos de otros. A diferencia del clustering por partición (no jerárquico), este no requiere de la pre-especificación del número de clusters a producir.</p>
<p>El clustering jerárquico se divide en dos tipos:</p>
<p><strong>1) Clustering aglomerativo.</strong></p>
<p><strong>2) Clustering divisivo.</strong></p>
<p>Las principales metodologías a revisar serán:</p>
<ul>
<li><p>Liga simple o vecino más cercano</p></li>
<li><p>Liga compleja o vecino más lejano</p></li>
<li><p>Liga promedio</p></li>
<li><p>Liga centroide</p></li>
<li><p>Varianza mínima de Ward</p></li>
</ul>
<p><img src="img/04-hclus/01-clusters.jpeg" width="350pt" /><img src="img/04-hclus/02-clusters.jpeg" width="350pt" /><img src="img/04-hclus/03-clusters.jpeg" width="350pt" /><img src="img/04-hclus/04-clusters.jpeg" width="350pt" /></p>
<p>A partir del concepto de distancia entre puntos en un espacio de <em>N</em> dimensiones (variables), se realiza la agrupación de elementos para posteriormente calcular cuántos <strong>grupos</strong> es conveniente usar. Este proceso puede ser graficado de múltiples formas, sin embargo, la visualización más usada corresponde al <strong>dendograma</strong>, el cual es un gráfico como el presentado a continuación:</p>
<p><img src="img/04-hclus/06-Hierarchical-Clustering.webp" width="400pt" style="display: block; margin: auto;" /></p>
<ul>
<li><p>El eje horizontal representa los <strong>puntos de datos</strong>.</p></li>
<li><p>La altura a lo largo del eje vertical representa la <strong>distancia entre los grupos</strong>.</p></li>
<li><p>Las líneas verticales en el gráfico representan grupos.</p></li>
<li><p>La altura de estas líneas representa la distancia desde el grupo más cercano.</p></li>
</ul>
<p>Podemos encontrar el número de conglomerados que mejor representan los grupos en los datos usando el dendrograma.</p>
<p><img src="img/04-hclus/07-Hierarchical-Clustering-1.webp" width="400pt" style="display: block; margin: auto;" /></p>
<p>Las líneas verticales con las mayores distancias entre ellas, es decir, la mayor altura en el mismo nivel, dan el número de grupos que mejor representan los datos.</p>
<div id="agglomerative-divise-clustering" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Agglomerative &amp; Divise Clustering<a href="clustering-jerárquico.html#agglomerative-divise-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El cluster aglomerativo es el tipo de clustering jerárquico más comúnmente usado para agrupar objetos en clusters basados en su similitud. También es conocido como <strong>AGNES</strong> (Agglomerative Nesting). El inverso del agrupamiento aglomerativo es el agrupmiento divisivo, en cual es conocido también como <strong>DIANA</strong> (<em>Divise Analysis</em>).</p>
<p><img src="img/04-hclus/08-agnes_diana_clustering.png" width="600pt" style="display: block; margin: auto;" /></p>
<div id="algoritmo-1" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Algoritmo<a href="clustering-jerárquico.html#algoritmo-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este algoritmo AGNES funciona de la manera <strong>“bottom-up”</strong>. Esto es:</p>
<ol style="list-style-type: decimal">
<li><p>cada objeto es <strong>inicialmente considerado como un cluster de único elemento</strong> (hoja).</p></li>
<li><p>En cada paso del algoritmo, los 2 clusters que son más <strong>similares</strong> son combinados en uno nuevo más grande.</p></li>
<li><p>El paso anterior es repetido hasta que todos los puntos son miembros de un <strong>único</strong> y gran cluster.</p></li>
</ol>
<p>Mientras que el algoritmo DIANA es del tipo <strong>top-down</strong>, funcionando de la siguiente manera:</p>
<ol style="list-style-type: decimal">
<li><p>Comienza con una raíz, en la que todos los elementos están incluidos en el mismo grupo.</p></li>
<li><p>En cada paso del algoritmo, los 2 clusters que son más <strong>disimilares</strong> son divididos en dos nuevos grupos.</p></li>
<li><p>El paso anterior es repetido hasta que todos los puntos son un cluster de elemento único en sí mismos.</p></li>
</ol>
<div class="infobox quicktip">
<p><strong>¡¡ TIP !!</strong></p>
<ul>
<li><p>Clustering aglomerativo es bueno en identificar pequeños clusters</p></li>
<li><p>Clustering divisivo es bueno para detectar los glusters grandes.</p></li>
</ul>
</div>
</div>
</div>
<div id="implementación-en-r-5" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Implementación en R<a href="clustering-jerárquico.html#implementación-en-r-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección se revisan las librerías y funciones que hacen posible estos algoritmos. Como metodología general, tenemos los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><p>Preparación de datos</p></li>
<li><p>Cálculo de (di)similitudes entre pares de objetos en el conjunto de datos</p></li>
<li><p>Uso de <strong>función liga</strong> para agrupar los objetos en un árbol jerárquico basado en la distancia generada en los pasos anteriores.</p></li>
<li><p>Determinar el umbral de corte del árbol jerárquico para la creación de grupos.</p></li>
</ol>
<div id="preparación-y-estructuración-de-datos" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Preparación y estructuración de datos<a href="clustering-jerárquico.html#preparación-y-estructuración-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los datos deben ser presentados en un formato matricial, en donde los renglones representan a las observaciones y las columnas a las variables.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="clustering-jerárquico.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;USArrests&quot;</span>)</span>
<span id="cb78-2"><a href="clustering-jerárquico.html#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="clustering-jerárquico.html#cb78-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">scale</span>(USArrests)</span>
<span id="cb78-4"><a href="clustering-jerárquico.html#cb78-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-5"><a href="clustering-jerárquico.html#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
<pre><code>##                Murder   Assault   UrbanPop         Rape
## Alabama    1.24256408 0.7828393 -0.5209066 -0.003416473
## Alaska     0.50786248 1.1068225 -1.2117642  2.484202941
## Arizona    0.07163341 1.4788032  0.9989801  1.042878388
## Arkansas   0.23234938 0.2308680 -1.0735927 -0.184916602
## California 0.27826823 1.2628144  1.7589234  2.067820292
## Colorado   0.02571456 0.3988593  0.8608085  1.864967207</code></pre>
</div>
<div id="medidas-de-disimilaridad" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Medidas de (di)similaridad<a href="clustering-jerárquico.html#medidas-de-disimilaridad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Con el fin de decidir qué elementos deben ser combinados o divididos, se requieren métodos para medir la similaridad entre objetos. Existen muchos métodos para calcular la (di)similaridad de la información. Estas métricas ya se han considerados en capítulos anteriores.</p>
<p>En <em>R</em>, se puede usar la función <em>dist()</em> para calcular la distancia entre cada par de objetos en un conjunto de datos. El resultado de este cálculo es conocido como <strong>matriz de distancia de similitud</strong>.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="clustering-jerárquico.html#cb80-1" aria-hidden="true" tabindex="-1"></a>res_dist <span class="ot">&lt;-</span> <span class="fu">dist</span>(df, <span class="at">method =</span> <span class="st">&quot;euclidian&quot;</span>)</span>
<span id="cb80-2"><a href="clustering-jerárquico.html#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(res_dist)[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code></pre></div>
<pre><code>##             Alabama   Alaska  Arizona Arkansas California Colorado
## Alabama    0.000000 2.703754 2.293520 1.289810   3.263110 2.651067
## Alaska     2.703754 0.000000 2.700643 2.826039   3.012541 2.326519
## Arizona    2.293520 2.700643 0.000000 2.717758   1.310484 1.365031
## Arkansas   1.289810 2.826039 2.717758 0.000000   3.763641 2.831051
## California 3.263110 3.012541 1.310484 3.763641   0.000000 1.287619
## Colorado   2.651067 2.326519 1.365031 2.831051   1.287619 0.000000</code></pre>
<p>Esta función usa los métodos de distancia:</p>
<ul>
<li><p>Euclidiana</p></li>
<li><p>Máxima</p></li>
<li><p>Manhattan</p></li>
<li><p>Canberra</p></li>
<li><p>Binaria</p></li>
<li><p>Minkowski</p></li>
</ul>
<p>Es importante mencionar que existen otras distancias como la geodésica que pueden implementarse a partir de otras librerías. Para distancias cortas y en general, la distancia euclidiana funciona muy bien.</p>
</div>
<div id="función-liga" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Función Liga<a href="clustering-jerárquico.html#función-liga" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La función liga toma la información de la distancia que regresa de la función <em>dist()</em> y agrupa pares de objetos en clusters basados en su similaridad. Posteriormente, estos clusters nuevos son ligados a otros para crear clusters más grandes. Este proceso es iterativo hasta que todos los objetos en el conjunto original de datos son ligados juntos en un árbol jerárquico. Este proceso se lleva a cabo con la función: <em>hclust()</em>.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="clustering-jerárquico.html#cb82-1" aria-hidden="true" tabindex="-1"></a>res_hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(<span class="at">d =</span> res_dist, <span class="at">method =</span> <span class="st">&quot;complete&quot;</span>)</span>
<span id="cb82-2"><a href="clustering-jerárquico.html#cb82-2" aria-hidden="true" tabindex="-1"></a>res_hc</span></code></pre></div>
<pre><code>## 
## Call:
## hclust(d = res_dist, method = &quot;complete&quot;)
## 
## Cluster method   : complete 
## Distance         : euclidean 
## Number of objects: 50</code></pre>
<p><strong>Donde:</strong></p>
<blockquote>
<p><strong>d:</strong> Es la estructura de disimilaridad producida por la función <em>dist()</em></p>
<p><strong>method:</strong> El método de liga de aglomeración a ser usado para el cálculo de distancia entre clusters. Los siguientes valores están permitidos: “single,” “complete,” “average,” “median,” “centroid,” “ward.D,” “ward.D2.”</p>
</blockquote>
<p>Existen múltiples métodos de aglomeración (i.e. métodos liga). Los más comunes se describen a continuación:</p>
<ul>
<li><strong>Liga máxima o completa:</strong> La distancia entre dos clusters es definida como el valor máximo de todos los pares de distancia entre los elementos dentro del cluster 1 y los elementos en el cluster 2. Tiende a producir clusters compactos.</li>
</ul>
<p><img src="img/04-hclus/09-complete_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Liga mínima o simple:</strong> La distancia entre dos clusters es definida como el valor mínimo de todas las parejas de distancias entre los elementos en el cluster 1 y los elementos en el cluster 2. Tiende a producir clusters largos o pobres.</li>
</ul>
<p><img src="img/04-hclus/10-single_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Liga promedio o media:</strong> La distancia entre dos clusters es definida como la distancia promedio entre los elementos en el cluster 1 y los elementos en el cluster 2.</li>
</ul>
<p><span class="math display">\[Dist(C_1, C_2)= \frac{1}{n_1+n_2}\sum_{i=1}^{n_1}{\sum_{j=1}^{n_2}{D(i,j)}}\]</span></p>
<p><img src="img/04-hclus/11-average_linkage2.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Liga centroide:</strong> La distancia entre dos clusters está definida como la distancia del centroide del cluster 1 (un vector de medias con tamaño de <em>p</em> variables) y el centroide del cluster 2.</li>
</ul>
<p><img src="img/04-hclus/12-centroid_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Método de varianza mínima de Ward:</strong> Este método en vez de analizar la distancia entre grupos, analiza la varianza, por lo que se encarga de minimizar el total de la varianza intra-cluster (inercia). En cada paso, el par de clusters con distancia mínima entre clusters son unidos. Este método dice que la distancia entre dos clusters A y B, es qué tanto la varianza respecto del centroide incrementará cuando sean unidos.</li>
</ul>
<p><img src="img/04-hclus/13-wards_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<p>Sin importar el método usado, en cada etapa del proceso de clustering, los 2 elementos con la distancia liga más corta son unidos en un solo cluster.</p>
<div class="infobox quicktip">
<p><strong>¡¡ TIP !!</strong></p>
<p>Las ligas: completa y Ward´s son preferidas generalmente</p>
</div>
</div>
</div>
<div id="dendogramas" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Dendogramas<a href="clustering-jerárquico.html#dendogramas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La manera gráfica de representar el proceso de clustering jerárquico es mediante un dendograma. Los dendogramas pueden ser creados en <em>R</em> a partir de la función genérica <em>plot()</em>, sin embargo, se mostrarán otras funciones más novedosas para crear gráficos de mayor calidad.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="clustering-jerárquico.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb84-2"><a href="clustering-jerárquico.html#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="clustering-jerárquico.html#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(res_hc, <span class="at">cex =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-121-1.png" width="672" /></p>
<p>En el dendograma superior cada hoja corresponde a un objeto. En la medida en que nos movemos hacia arriba en el árbol, los objetos que son similar a otros están combinados en ramas, las cuales se fusionan a mayor altura.</p>
<p>La altura de la fusión, proveída en el eje vertical, indica la (di)similaridad/distancia entre dos objetos/clusters. Entre más alta sea la altura de la fusión, menos similares son los objetos/clusters. Esta altura es conocida como <strong>la distancia de cophenetic</strong> entre dos objetos.</p>
<p>A fin de identificar sub-grupos, se puede cortar el dendograma en cierta altura, como se describe en las siguientes secciones.</p>
<p>Para validar que las distancias en la altura reflejen las distancias originales de manera precisa, se hace uso de la correlación entre las distancias originales y la distancia de cophenetic:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="clustering-jerárquico.html#cb85-1" aria-hidden="true" tabindex="-1"></a>res_coph <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(res_hc)</span>
<span id="cb85-2"><a href="clustering-jerárquico.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(res_coph)[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code></pre></div>
<pre><code>##             Alabama   Alaska  Arizona Arkansas California Colorado
## Alabama    0.000000 3.255433 4.420074 6.076642   4.420074 4.420074
## Alaska     3.255433 0.000000 4.420074 6.076642   4.420074 4.420074
## Arizona    4.420074 4.420074 0.000000 6.076642   2.445860 2.445860
## Arkansas   6.076642 6.076642 6.076642 0.000000   6.076642 6.076642
## California 4.420074 4.420074 2.445860 6.076642   0.000000 1.398859
## Colorado   4.420074 4.420074 2.445860 6.076642   1.398859 0.000000</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="clustering-jerárquico.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(res_coph, res_dist)</span></code></pre></div>
<pre><code>## [1] 0.6979437</code></pre>
<p><strong>Ejercicio</strong></p>
<ul>
<li>Usar las distintas ligas y determinar cuál de ellas funciona mejor (<em>Hint:</em> La que muestre correlación más alta entre las distancias originales y la distancia cophenetica)</li>
</ul>
<div id="selección-de-grupos" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Selección de grupos<a href="clustering-jerárquico.html#selección-de-grupos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Uno de los problemas del clustering jerárquico es que, NO dice cuántos clusters hay o dónde cortar el dendograma para formar los clusters.</p>
<p>Es posible cortar el árbol jerárquico a una altura dada con el fin de particionar los datos en clusters. La función <em>cutree()</em> puede ser usada para cortar el árbol en varios grupos al especificar ya el número deseado de grupos o la altura a cortar. Esta función regresa un vector que contiene el número de cluster de cada observación.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="clustering-jerárquico.html#cb89-1" aria-hidden="true" tabindex="-1"></a>groups_1 <span class="ot">&lt;-</span> <span class="fu">cutree</span>(res_hc, <span class="at">k =</span> <span class="dv">4</span>)</span>
<span id="cb89-2"><a href="clustering-jerárquico.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(groups_1)</span></code></pre></div>
<pre><code>##    Alabama     Alaska    Arizona   Arkansas California   Colorado 
##          1          1          2          3          2          2</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="clustering-jerárquico.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(groups_1)</span></code></pre></div>
<pre><code>## groups_1
##  1  2  3  4 
##  8 11 21 10</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="clustering-jerárquico.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb93-2"><a href="clustering-jerárquico.html#cb93-2" aria-hidden="true" tabindex="-1"></a> res_hc,</span>
<span id="cb93-3"><a href="clustering-jerárquico.html#cb93-3" aria-hidden="true" tabindex="-1"></a> <span class="at">k =</span> <span class="dv">4</span>,</span>
<span id="cb93-4"><a href="clustering-jerárquico.html#cb93-4" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb93-5"><a href="clustering-jerárquico.html#cb93-5" aria-hidden="true" tabindex="-1"></a> <span class="at">k_colors =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;purple&quot;</span>),</span>
<span id="cb93-6"><a href="clustering-jerárquico.html#cb93-6" aria-hidden="true" tabindex="-1"></a> <span class="at">color_labels_by_k =</span> <span class="cn">TRUE</span>,</span>
<span id="cb93-7"><a href="clustering-jerárquico.html#cb93-7" aria-hidden="true" tabindex="-1"></a> <span class="at">rect =</span> <span class="cn">TRUE</span></span>
<span id="cb93-8"><a href="clustering-jerárquico.html#cb93-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-124-1.png" width="672" /></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="clustering-jerárquico.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb94-2"><a href="clustering-jerárquico.html#cb94-2" aria-hidden="true" tabindex="-1"></a> res_hc,</span>
<span id="cb94-3"><a href="clustering-jerárquico.html#cb94-3" aria-hidden="true" tabindex="-1"></a> <span class="at">h =</span> <span class="dv">7</span>,</span>
<span id="cb94-4"><a href="clustering-jerárquico.html#cb94-4" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb94-5"><a href="clustering-jerárquico.html#cb94-5" aria-hidden="true" tabindex="-1"></a> <span class="at">k_colors =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>),</span>
<span id="cb94-6"><a href="clustering-jerárquico.html#cb94-6" aria-hidden="true" tabindex="-1"></a> <span class="at">color_labels_by_k =</span> <span class="cn">TRUE</span>,</span>
<span id="cb94-7"><a href="clustering-jerárquico.html#cb94-7" aria-hidden="true" tabindex="-1"></a> <span class="at">rect =</span> <span class="cn">TRUE</span></span>
<span id="cb94-8"><a href="clustering-jerárquico.html#cb94-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-125-1.png" width="672" /></p>
<p>Usando la función <em>f_viz_cluster()</em> también es posible visualizar los clusters a través de un gráfico de dispersión. Las observaciones son presentadas en puntos usando el análisis de componentes principales.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="clustering-jerárquico.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(</span>
<span id="cb95-2"><a href="clustering-jerárquico.html#cb95-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">list</span>(<span class="at">data =</span> df, <span class="at">cluster =</span> groups_1),</span>
<span id="cb95-3"><a href="clustering-jerárquico.html#cb95-3" aria-hidden="true" tabindex="-1"></a> <span class="at">palette =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;purple&quot;</span>),</span>
<span id="cb95-4"><a href="clustering-jerárquico.html#cb95-4" aria-hidden="true" tabindex="-1"></a> <span class="at">ellipse.type =</span> <span class="st">&quot;convex&quot;</span>,</span>
<span id="cb95-5"><a href="clustering-jerárquico.html#cb95-5" aria-hidden="true" tabindex="-1"></a> <span class="at">repel =</span> T,</span>
<span id="cb95-6"><a href="clustering-jerárquico.html#cb95-6" aria-hidden="true" tabindex="-1"></a> <span class="at">show.clust.cent =</span> F</span>
<span id="cb95-7"><a href="clustering-jerárquico.html#cb95-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-126-1.png" width="672" /></p>
<p>Finalmente, es importante mencionar que la librería <em>cluster</em> ofrece un par de funciones que resumen todo el proceso anterior (scale, dist y hclus). Las funciones se usan de la siguiente forma:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="clustering-jerárquico.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb96-2"><a href="clustering-jerárquico.html#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="clustering-jerárquico.html#cb96-3" aria-hidden="true" tabindex="-1"></a>res_agnes <span class="ot">&lt;-</span> <span class="fu">agnes</span>(</span>
<span id="cb96-4"><a href="clustering-jerárquico.html#cb96-4" aria-hidden="true" tabindex="-1"></a> <span class="at">x =</span> USArrests,</span>
<span id="cb96-5"><a href="clustering-jerárquico.html#cb96-5" aria-hidden="true" tabindex="-1"></a> <span class="at">stand =</span> T,</span>
<span id="cb96-6"><a href="clustering-jerárquico.html#cb96-6" aria-hidden="true" tabindex="-1"></a> <span class="at">metric =</span> <span class="st">&quot;euclidian&quot;</span>,</span>
<span id="cb96-7"><a href="clustering-jerárquico.html#cb96-7" aria-hidden="true" tabindex="-1"></a> <span class="at">method =</span> <span class="st">&quot;ward&quot;</span></span>
<span id="cb96-8"><a href="clustering-jerárquico.html#cb96-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb96-9"><a href="clustering-jerárquico.html#cb96-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-10"><a href="clustering-jerárquico.html#cb96-10" aria-hidden="true" tabindex="-1"></a>res_diana <span class="ot">&lt;-</span> <span class="fu">diana</span>(</span>
<span id="cb96-11"><a href="clustering-jerárquico.html#cb96-11" aria-hidden="true" tabindex="-1"></a> <span class="at">x =</span> USArrests,</span>
<span id="cb96-12"><a href="clustering-jerárquico.html#cb96-12" aria-hidden="true" tabindex="-1"></a> <span class="at">stand =</span> T,</span>
<span id="cb96-13"><a href="clustering-jerárquico.html#cb96-13" aria-hidden="true" tabindex="-1"></a> <span class="at">metric =</span> <span class="st">&quot;euclidian&quot;</span></span>
<span id="cb96-14"><a href="clustering-jerárquico.html#cb96-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb96-15"><a href="clustering-jerárquico.html#cb96-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-16"><a href="clustering-jerárquico.html#cb96-16" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb96-17"><a href="clustering-jerárquico.html#cb96-17" aria-hidden="true" tabindex="-1"></a> res_diana, </span>
<span id="cb96-18"><a href="clustering-jerárquico.html#cb96-18" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.6</span>, </span>
<span id="cb96-19"><a href="clustering-jerárquico.html#cb96-19" aria-hidden="true" tabindex="-1"></a> <span class="at">k =</span> <span class="dv">4</span>,</span>
<span id="cb96-20"><a href="clustering-jerárquico.html#cb96-20" aria-hidden="true" tabindex="-1"></a> <span class="at">color_labels_by_k =</span> <span class="cn">TRUE</span>,</span>
<span id="cb96-21"><a href="clustering-jerárquico.html#cb96-21" aria-hidden="true" tabindex="-1"></a> <span class="at">rect =</span> <span class="cn">TRUE</span></span>
<span id="cb96-22"><a href="clustering-jerárquico.html#cb96-22" aria-hidden="true" tabindex="-1"></a> )</span></code></pre></div>
<p><img src="amt22_04intro2mlns_files/figure-html/unnamed-chunk-127-1.png" width="672" /></p>

</div>
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="clustering-no-jerárquico.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="anexo-visualización-con-ggplot.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["amt22_04intro2mlns.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
